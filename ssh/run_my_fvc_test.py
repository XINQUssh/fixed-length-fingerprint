import os
import sys
import numpy as np
import torch
import cv2
import matplotlib.pyplot as plt

sys.path.append(os.getcwd())
from flx.extractor.fixed_length_extractor import get_DeepPrint_TexMinu
from flx.setup.datasets import get_fvc2004_db1a
from flx.data.image_loader import FVC2004Loader

# ========================= é…ç½®é¡¹ =========================
MODEL_PATH = "./models/best_model.pyt"  # ä½ çš„æ¨¡å‹è·¯å¾„
DATA_DIR   = "./data/fingerprints/test"     # ä½ çš„æ•°æ®é›†è·¯å¾„
DEVICE     = "cuda" if torch.cuda.is_available() else "cpu"  # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
INPUT_SIZE = 448  # æ¨¡å‹è¾“å…¥å°ºå¯¸ï¼ˆæ ¹æ®ä½ çš„å®é™…æƒ…å†µè°ƒæ•´ï¼Œé»˜è®¤448ï¼‰
OUTPUT_DIR = "./minutia_output/1"  # ç»“æœä¿å­˜ç›®å½•

# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ============================================================
#                     æ ¸å¿ƒå·¥å…·ï¼šç‰¹å¾Hook + å¯è§†åŒ–
# ============================================================
class FeatureHook:
    """ç”¨äºæ•è·æ¨¡å‹ä¸­é—´å±‚è¾“å‡ºçš„ Hookï¼ˆä»…ä¿ç•™æ ¸å¿ƒåŠŸèƒ½ï¼‰"""
    def __init__(self, module):
        self.hook = module.register_forward_hook(self.hook_fn)
        self.output = None

    def hook_fn(self, module, input, output):
        self.output = output

    def close(self):
        self.hook.remove()

def save_and_show_minutia_map(extractor, ds, device=DEVICE):
    """
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. æå–6é€šé“minutia_mapå¹¶å•ç‹¬å¯è§†åŒ–
    2. ç”Ÿæˆé€šé“æœ€å¤§å€¼èåˆå›¾
    3. å°†èåˆå›¾å åŠ åˆ°åŸå§‹æŒ‡çº¹å›¾åƒå¹¶ä¿å­˜ï¼ˆä¿®å¤å°ºå¯¸åŒ¹é…é—®é¢˜ï¼‰
    """
    # å®šä½ minutia_map æœ€åå·ç§¯å±‚ï¼ˆç”Ÿæˆ6é€šé“ç‰¹å¾å›¾çš„å±‚ï¼‰
    target_layer = extractor.model.minutia_map.features[3]
    hook = FeatureHook(target_layer)

    # å–æ•°æ®é›†ç¬¬ä¸€å¼ å›¾ä½œä¸ºå¯è§†åŒ–æ ·æœ¬
    data = ds[0]
    img_tensor = data[0] if isinstance(data, (tuple, list)) else data
    # ä¿å­˜åŸå§‹å›¾åƒï¼ˆç”¨äºåç»­å åŠ ï¼‰
    if not torch.is_tensor(img_tensor):
        original_img_np = img_tensor.copy()  # åŸå§‹é¢„å¤„ç†åçš„å›¾åƒï¼ˆ0-1æµ®ç‚¹å‹ï¼‰
        img_tensor = torch.from_numpy(img_tensor)
    else:
        original_img_np = img_tensor.cpu().numpy()  # è½¬numpy
    
    # æ„é€ æ¨¡å‹è¾“å…¥ï¼ˆé¿å…ç»´åº¦å‹ç¼©ï¼Œé‡å¤1æ¬¡batchï¼‰
    img_input = img_tensor.unsqueeze(0).repeat(2, 1, 1, 1).to(device).float()

    print(f"ğŸ“Œ ç›®æ ‡å±‚: {target_layer}")
    print("ğŸ”„ åˆ‡æ¢æ¨¡å‹ä¸ºtrainæ¨¡å¼ä»¥æ¿€æ´»minutiaeåˆ†æ”¯...")
    extractor.model.train()  # å¿…é¡»trainæ¨¡å¼æ‰èƒ½è¾“å‡ºminutia_maps

    # å‰å‘ä¼ æ’­è·å–ç‰¹å¾
    with torch.no_grad():
        try:
            extractor.model(img_input)
        except Exception as e:
            print(f"âŒ å‰å‘ä¼ æ’­é”™è¯¯: {e}")
            hook.close()
            return

    # æ£€æŸ¥æ˜¯å¦æˆåŠŸæ•è·ç‰¹å¾
    if hook.output is None:
        print("âŒ æœªæ•è·åˆ°minutiaeç‰¹å¾å›¾ï¼Œè¯·æ£€æŸ¥æ¨¡å‹ç»“æ„ï¼")
        hook.close()
        return

    # æå–å¹¶å¤„ç†ç‰¹å¾å›¾ï¼ˆå–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„6é€šé“ç‰¹å¾ï¼‰
    m_map = hook.output[0].cpu().detach().numpy()  # [6, 128, 128]
    hook.close()
    extractor.model.eval()  # æ¢å¤evalæ¨¡å¼

    # ===================== 1. ç»˜åˆ¶6é€šé“ç‰¹å¾å›¾ï¼ˆåŸæœ‰é€»è¾‘ï¼‰ =====================
    fig, axes = plt.subplots(2, 3, figsize=(15, 8))
    fig.suptitle("DeepPrint Minutia Map (6 Channels)", fontsize=16)
    for i in range(6):
        ax = axes[i // 3, i % 3]
        im = ax.imshow(m_map[i], cmap='gray_r')  # gray_ræ›´æ¸…æ™°å±•ç¤ºç‰¹å¾
        ax.set_title(f"Channel {i}", fontsize=12)
        ax.axis('off')  # å…³é—­åæ ‡è½´
        plt.colorbar(im, ax=ax, shrink=0.8)  # é¢œè‰²æ¡
    
    # ä¿å­˜6é€šé“å¯è§†åŒ–å›¾
    six_chan_path = os.path.join(OUTPUT_DIR, "minutia_map_6channels.png")
    plt.tight_layout()
    plt.savefig(six_chan_path, dpi=150, bbox_inches='tight')
    plt.close()  # å…³é—­ç”»å¸ƒé‡Šæ”¾å†…å­˜
    print(f"âœ… 6é€šé“ç‰¹å¾å›¾å·²ä¿å­˜: {six_chan_path}")

    # ===================== 2. ç”Ÿæˆé€šé“æœ€å¤§å€¼èåˆå›¾ =====================
    print("ğŸ”§ ç”Ÿæˆé€šé“æœ€å¤§å€¼èåˆå›¾...")
    # æ²¿é€šé“ç»´åº¦å–æœ€å¤§å€¼ï¼ˆèåˆæ‰€æœ‰è§’åº¦çš„ç‰¹å¾ç‚¹ï¼‰
    merged = np.max(m_map, axis=0)  # [128, 128]
    # å½’ä¸€åŒ–åˆ°0-1ï¼ˆæ¶ˆé™¤æ•°å€¼èŒƒå›´å·®å¼‚ï¼‰
    merged = (merged - merged.min()) / (merged.max() - merged.min() + 1e-6)
    # è½¬æ¢ä¸ºuint8ï¼ˆ0-255ï¼‰ç”¨äºä¿å­˜å’Œå åŠ 
    merged_u8 = (merged * 255).astype(np.uint8)

    # ä¿å­˜èåˆå›¾
    merged_path = os.path.join(OUTPUT_DIR, "minutia_merged.png")
    cv2.imwrite(merged_path, merged_u8)
    print(f"âœ… é€šé“æœ€å¤§å€¼èåˆå›¾å·²ä¿å­˜: {merged_path}")

    # ===================== 3. èåˆå›¾å åŠ åˆ°åŸå§‹æŒ‡çº¹å›¾åƒï¼ˆä¿®å¤å°ºå¯¸åŒ¹é…ï¼‰ =====================
    print("ğŸ¨ å°†èåˆå›¾å åŠ åˆ°åŸå§‹æŒ‡çº¹å›¾åƒ...")
    # æ­¥éª¤1ï¼šå¤„ç†åŸå§‹å›¾åƒï¼ˆæ ‡å‡†åŒ–æ ¼å¼ï¼Œç¡®ä¿å°ºå¯¸/é€šé“æ­£ç¡®ï¼‰
    # åŸå§‹å›¾åƒæ˜¯0-1æµ®ç‚¹å‹ï¼Œè½¬255å°ºåº¦
    original_img_u8 = (original_img_np * 255).astype(np.uint8)
    # è‹¥åŸå§‹å›¾åƒæ˜¯3ç»´ï¼ˆ1, H, Wï¼‰ï¼Œå‹ç¼©ä¸º2ç»´
    if original_img_u8.ndim == 3:
        original_img_u8 = original_img_u8.squeeze(0)
    # æ‰“å°åŸå§‹å›¾åƒå°ºå¯¸ï¼ˆè°ƒè¯•ç”¨ï¼‰
    print(f"   - åŸå§‹å›¾åƒå°ºå¯¸: {original_img_u8.shape}")

    # æ­¥éª¤2ï¼šå¼ºåˆ¶å¯¹é½å°ºå¯¸ï¼ˆæ ¸å¿ƒä¿®å¤ï¼‰
    # è·å–åŸå§‹å›¾åƒçš„å®é™…å°ºå¯¸
    h, w = original_img_u8.shape[:2]
    # å°†èåˆå›¾ç¼©æ”¾è‡³åŸå§‹å›¾åƒçš„å®é™…å°ºå¯¸ï¼ˆè€Œéå›ºå®šINPUT_SIZEï¼‰
    merged_resized = cv2.resize(merged_u8, (w, h), interpolation=cv2.INTER_CUBIC)
    print(f"   - èåˆå›¾ç¼©æ”¾åå°ºå¯¸: {merged_resized.shape}")

    # æ­¥éª¤3ï¼šè½¬æ¢ä¸ºå½©è‰²çƒ­åŠ›å›¾ï¼ˆç¡®ä¿3é€šé“ï¼‰
    heat_map = cv2.applyColorMap(merged_resized, cv2.COLORMAP_JET)
    # ç¡®ä¿çƒ­åŠ›å›¾æ˜¯3é€šé“ï¼ˆé˜²æ­¢ç‰¹æ®Šæƒ…å†µï¼‰
    if heat_map.ndim != 3 or heat_map.shape[2] != 3:
        heat_map = cv2.cvtColor(heat_map, cv2.COLOR_GRAY2BGR)
    print(f"   - çƒ­åŠ›å›¾å°ºå¯¸/é€šé“: {heat_map.shape}")

    # æ­¥éª¤4ï¼šåŸå§‹ç°åº¦å›¾è½¬å½©è‰²ï¼ˆç¡®ä¿3é€šé“ï¼Œä¸çƒ­åŠ›å›¾åŒ¹é…ï¼‰
    if original_img_u8.ndim == 2:  # å•é€šé“ç°åº¦å›¾
        original_bgr = cv2.cvtColor(original_img_u8, cv2.COLOR_GRAY2BGR)
    else:  # å·²ä¸ºå½©è‰²å›¾
        original_bgr = original_img_u8
    print(f"   - åŸå§‹å›¾è½¬å½©è‰²åå°ºå¯¸/é€šé“: {original_bgr.shape}")

    # æœ€ç»ˆæ ¡éªŒï¼šç¡®ä¿ä¸¤å¼ å›¾å°ºå¯¸/é€šé“å®Œå…¨ä¸€è‡´
    if original_bgr.shape != heat_map.shape:
        print(f"âš ï¸  å°ºå¯¸/é€šé“ä¸åŒ¹é…ï¼Œå¼ºåˆ¶å¯¹é½: {original_bgr.shape} â†’ {heat_map.shape}")
        # ç»ˆæå…œåº•ï¼šç¼©æ”¾çƒ­åŠ›å›¾åˆ°åŸå§‹å›¾å°ºå¯¸
        heat_map = cv2.resize(heat_map, (original_bgr.shape[1], original_bgr.shape[0]), interpolation=cv2.INTER_CUBIC)

    # æ­¥éª¤5ï¼šå›¾åƒå åŠ ï¼ˆåŸå§‹å›¾65% + çƒ­åŠ›å›¾35%ï¼Œé€æ˜åº¦å¯è°ƒï¼‰
    overlay = cv2.addWeighted(original_bgr, 0.65, heat_map, 0.35, 0.0)
    
    # ä¿å­˜å åŠ å›¾
    overlay_path = os.path.join(OUTPUT_DIR, "minutia_overlay.png")
    cv2.imwrite(overlay_path, overlay)
    print(f"âœ… èåˆå›¾å åŠ åˆ°åŸå›¾å·²ä¿å­˜: {overlay_path}")

    # é¢å¤–ï¼šä¿å­˜åŸå§‹æŒ‡çº¹å›¾åƒï¼ˆæ–¹ä¾¿å¯¹æ¯”ï¼‰
    original_path = os.path.join(OUTPUT_DIR, "original_fingerprint.png")
    cv2.imwrite(original_path, original_img_u8)
    print(f"âœ… åŸå§‹æŒ‡çº¹å›¾åƒå·²ä¿å­˜: {original_path}")

    print("\nğŸ‰ æ‰€æœ‰ç»“æœä¿å­˜å®Œæˆï¼è¾“å‡ºç›®å½•ï¼š", OUTPUT_DIR)
    print("ç”Ÿæˆæ–‡ä»¶åˆ—è¡¨ï¼š")
    print(f"  - {six_chan_path}: 6é€šé“minutia mapå•ç‹¬å¯è§†åŒ–")
    print(f"  - {merged_path}: 6é€šé“æœ€å¤§å€¼èåˆå›¾ï¼ˆ128x128ï¼‰")
    print(f"  - {original_path}: åŸå§‹é¢„å¤„ç†æŒ‡çº¹å›¾åƒï¼ˆ{h}x{w}ï¼‰")
    print(f"  - {overlay_path}: èåˆç‰¹å¾å›¾å åŠ åˆ°åŸå›¾ï¼ˆçƒ­åŠ›å›¾ï¼‰")

# ============================================================
#                   ç®€åŒ–ç‰ˆå›¾åƒé¢„å¤„ç†ï¼ˆä»…ç”¨äºå¯è§†åŒ–ï¼‰
# ============================================================
def make_simple_loader():
    """
    æç®€é¢„å¤„ç†ï¼šä»…ä¿ç•™å¯è§†åŒ–æ‰€éœ€çš„åŸºç¡€å¤„ç†
    æ ¸å¿ƒä¿®å¤ï¼šæ·»åŠ selfå‚æ•°ï¼ŒåŒ¹é…ç±»æ–¹æ³•çš„è°ƒç”¨è§„åˆ™
    """
    # å®šä¹‰ç±»æ–¹æ³•æ ¼å¼çš„åŠ è½½å‡½æ•°ï¼šç¬¬ä¸€ä¸ªå‚æ•°ä¸ºselfï¼ˆç±»å®ä¾‹ï¼‰ï¼Œç¬¬äºŒä¸ªä¸ºfilepath
    def _load(self, filepath):
        # åŸºç¡€é¢„å¤„ç†ï¼šç°åº¦è¯»å– + CLAHEå¢å¼º + ç¼©æ”¾è‡³æ¨¡å‹è¾“å…¥å°ºå¯¸
        img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)
        if img is None:
            raise ValueError(f"âŒ è¯»å–å›¾ç‰‡å¤±è´¥: {filepath}")
        
        # CLAHEå¢å¼ºï¼ˆå›ºå®šå‚æ•°ï¼Œä¿è¯å¯è§†åŒ–æ•ˆæœï¼‰
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
        img = clahe.apply(img)
        # ç¼©æ”¾è‡³DeepPrintè¾“å…¥å°ºå¯¸ï¼ˆ448x448ï¼‰
        from flx.data.image_helpers import pad_and_resize_to_deepprint_input_size
        img_processed = pad_and_resize_to_deepprint_input_size(img, fill=1.0)
        return img_processed

    return _load

# ============================================================
#                       ä¸»æµç¨‹ï¼ˆä»…å¯è§†åŒ–ï¼‰
# ============================================================
def main():
    """ä¸»å‡½æ•°ï¼šä»…åŠ è½½æ¨¡å‹ + å¯è§†åŒ–minutiaeç‰¹å¾å›¾ + èåˆå åŠ """
    # 1. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    print("ğŸ“¥ åŠ è½½æ¨¡å‹...")
    extractor = get_DeepPrint_TexMinu(8000, 256)  # å‚æ•°ä»…ä¸ºæ„é€ æ¨¡å‹ï¼Œä¸å½±å“å¯è§†åŒ–
    ckpt = torch.load(MODEL_PATH, map_location="cpu")
    sd = ckpt["model_state_dict"] if "model_state_dict" in ckpt else ckpt

    # åŠ è½½æƒé‡ï¼ˆåŒ¹é…ç»´åº¦ï¼‰
    md = extractor.model.state_dict()
    md.update({k: v for k, v in sd.items() if k in md and v.shape == md[k].shape})
    extractor.model.load_state_dict(md)
    extractor.model.to(DEVICE).eval()
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼")

    # 2. é…ç½®æ•°æ®é›†åŠ è½½å™¨ï¼ˆç®€åŒ–ç‰ˆé¢„å¤„ç†ï¼‰
    print("\nğŸ“‚ åŠ è½½æ•°æ®é›†...")
    # æ›¿æ¢FVC2004Loaderçš„_load_imageæ–¹æ³•ï¼ˆç±»æ–¹æ³•ï¼Œéœ€æ¥æ”¶selfå‚æ•°ï¼‰
    FVC2004Loader._load_image = make_simple_loader()
    ds = get_fvc2004_db1a(DATA_DIR)
    
    if len(ds) == 0:
        print("âŒ æ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥DATA_DIRè·¯å¾„ï¼")
        return
    print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆï¼Œå…± {len(ds)} ä¸ªæ ·æœ¬")

    # 3. æ ¸å¿ƒï¼šå¯è§†åŒ–minutiaeç‰¹å¾å›¾ + èåˆå åŠ 
    print("\nğŸ¨ å¼€å§‹å¯è§†åŒ–minutiaeç‰¹å¾å›¾...")
    save_and_show_minutia_map(extractor, ds)

if __name__ == "__main__":
    main()