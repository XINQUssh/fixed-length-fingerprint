import os
import sys
import numpy as np
import torch
import cv2
from sklearn.metrics import roc_curve
from pathlib import Path

# è®¾ç½®é¡¹ç›®è·¯å¾„
notebook_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(notebook_dir)
sys.path.append(project_root)

# å¯¼å…¥å¿…è¦æ¨¡å—
from flx.extractor.fixed_length_extractor import get_DeepPrint_TexMinu, DeepPrintExtractor
from flx.scripts.generate_benchmarks import create_verification_benchmark
from flx.benchmarks.matchers import CosineSimilarityMatcher
from flx.data.embedding_loader import EmbeddingLoader
from flx.visualization.plot_DET_curve import plot_verification_results

# é¡¹ç›®åŸç”Ÿç±»ï¼ˆæ— è‡ªå®šä¹‰ç±»ï¼Œé¿å…å¯¼å…¥é”™è¯¯ï¼‰
from flx.data.dataset import Identifier, IdentifierSet, Dataset
from flx.data.image_loader import ImageLoader
from flx.data.image_helpers import pad_and_resize_to_deepprint_input_size


# ========================= è·¯å¾„é…ç½® =========================
MODEL_DIR = os.path.abspath("ssh/example-model")  # æ¨¡å‹ç›®å½•
CUSTOM_DATA_DIR = r"D:\AAAYan\ZhiWen\FixLength\fixed-length-fingerprint\ssh\data\fingerprints\2Database"  # ä½ çš„æŒ‡çº¹æ•°æ®é›†è·¯å¾„
DET_FIGURE_PATH = "DET_curve_custom"  # DETæ›²çº¿ä¿å­˜è·¯å¾„

# ========================= è¯„ä¼°å‚æ•° =========================
NUM_IMPRESSIONS_PER_SUBJECT = 4  # æ¯ä¸ªæ‰‹æŒ‡çš„é‡‡é›†æ¬¡æ•°ï¼ˆä½ çš„æ•°æ®é›†æ˜¯4æ¬¡ï¼‰
TARGET_FAR_VALUES = [0.05, 0.01, 0.001, 0.0001, 0.00002, 0.00001]  # ç›®æ ‡FARå€¼


# ============================================================
# ç¬¬ä¸€æ­¥ï¼šå®ç°é€‚é…ä½ çš„æ•°æ®é›†çš„ImageLoaderï¼ˆæ ¸å¿ƒï¼‰
# ============================================================
class MyFingerprintLoader(ImageLoader):
    """é€‚é…ä½ çš„æŒ‡çº¹æ•°æ®é›†çš„ImageLoaderï¼ˆå…¼å®¹å¼‚å¸¸æ•°æ®ï¼‰"""
    @staticmethod
    def _extension() -> str:
        return ".bmp"  # å°å†™ï¼Œé…åˆlower()å…¼å®¹å¤§å†™

    @staticmethod
    def _file_to_id_fun(subdir: str, filename: str) -> Identifier:
        """è§£ææ–‡ä»¶åï¼ˆå…¼å®¹å¤§å†™åç¼€+å®¹é”™å¼‚å¸¸å‘½åï¼‰"""
        filename_lower = filename.lower()
        name = filename_lower.replace(MyFingerprintLoader._extension(), "")
        parts = name.split("_")
        
        # å®¹é”™1ï¼šæ–‡ä»¶åæ ¼å¼é”™è¯¯ï¼ˆä¸è¶³3éƒ¨åˆ†ï¼‰
        if len(parts) < 3:
            print(f"âš ï¸  è·³è¿‡æ ¼å¼é”™è¯¯æ–‡ä»¶ï¼š{filename}ï¼ˆéœ€x_x_x.bmpï¼‰")
            return None
        
        # å®¹é”™2ï¼šé‡‡é›†æ¬¡æ•°ä¸æ˜¯æ•°å­—
        try:
            capture_id = int(parts[-1]) - 1
        except ValueError:
            print(f"âš ï¸  è·³è¿‡é‡‡é›†æ¬¡æ•°é”™è¯¯æ–‡ä»¶ï¼š{filename}")
            return None
        
        # è§£æfinger_idå¹¶å“ˆå¸Œ
        finger_id = "_".join(parts[:-1])
        subject_id = hash(finger_id) % 1000000
        
        return Identifier(subject=subject_id, impression=capture_id)

    @staticmethod
    def _load_image(filepath: str) -> torch.Tensor:
        """åŠ è½½å›¾ç‰‡+é¢„å¤„ç†ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰"""
        img = cv2.imread(filepath, flags=cv2.IMREAD_GRAYSCALE)
        if img is None:
            print(f"âš ï¸  æ— æ³•åŠ è½½å›¾ç‰‡ï¼Œè·³è¿‡ï¼š{filepath}")
            return None  # è¿”å›Noneè·³è¿‡æŸåå›¾ç‰‡
        
        # ä½ çš„é¢„å¤„ç†é€»è¾‘ï¼ˆå®Œå…¨ä¿ç•™ï¼‰
        crop_size_target = 400
        angle_target = 0
        
        img = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8)).apply(img)
        if angle_target != 0:
            h, w = img.shape
            M = cv2.getRotationMatrix2D((w // 2, h // 2), angle_target, 1.0)
            img = cv2.warpAffine(img, M, (w, h), borderValue=255)
        
        blur = cv2.GaussianBlur(img, (5, 5), 0)
        _, th = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        coords = np.argwhere(th > 0)
        
        cy, cx = img.shape[0] // 2, img.shape[1] // 2
        if len(coords) > 0:
            cy, cx = coords.mean(0).astype(int)
        cs = crop_size_target
        sy = max(0, min(cy - cs // 2, img.shape[0] - cs))
        sx = max(0, min(cx - cs // 2, img.shape[1] - cs))
        img = img[sy:sy + cs, sx:sx + cs]
        
        # é€‚é…æ¨¡å‹è¾“å…¥å°ºå¯¸å¹¶è½¬Tensor
        img = pad_and_resize_to_deepprint_input_size(img, fill=1.0)
        if isinstance(img, np.ndarray):
            import torchvision.transforms.functional as VTF
            img = VTF.to_tensor(img)
        
        return img

    def __init__(self, root_dir: str):
        """åˆå§‹åŒ–ï¼ˆç§»é™¤æ–­è¨€ï¼Œæ”¹ä¸ºè­¦å‘Š+è¯¦ç»†ç»Ÿè®¡ï¼‰"""
        super().__init__(root_dir=Path(root_dir))
        total_samples = len(self.ids)
        total_finger_ids = self.ids.num_subjects
        
        # æ‰“å°æ ¸å¿ƒç»Ÿè®¡
        print(f"ğŸ“Œ æ•°æ®é›†éªŒè¯ï¼šæ€»å›¾ç‰‡æ•°={total_samples}ï¼ˆé¢„æœŸ6000ï¼‰ï¼Œæ€»æŒ‡çº¹IDæ•°={total_finger_ids}ï¼ˆé¢„æœŸ1500ï¼‰")
        
        # è­¦å‘Šè€Œéæ–­è¨€
        if total_samples != 6000 or total_finger_ids != 1500:
            print(f"âš ï¸  è­¦å‘Šï¼šæ•°æ®é›†æ•°é‡ä¸ç¬¦ï¼")
            print(f"   - ç¼ºå¤±å›¾ç‰‡æ•°ï¼š{6000 - total_samples}")
            print(f"   - ç¼ºå¤±æŒ‡çº¹IDæ•°ï¼š{1500 - total_finger_ids}")
            
            # ç»Ÿè®¡é‡‡é›†æ¬¡æ•°ä¸è¶³4æ¬¡çš„æŒ‡çº¹ID
            subject_impression_count = {}
            for id_obj in self.ids:
                subject = id_obj.subject
                subject_impression_count[subject] = subject_impression_count.get(subject, 0) + 1
            
            insufficient_ids = [subj for subj, cnt in subject_impression_count.items() if cnt < 4]
            if insufficient_ids:
                print(f"âš ï¸  é‡‡é›†æ¬¡æ•°ä¸è¶³4æ¬¡çš„æŒ‡çº¹IDï¼ˆå‰10ä¸ªï¼‰ï¼š{insufficient_ids[:10]}")

# ============================================================
# è¯„ä¼°å·¥å…·å‡½æ•°ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
# ============================================================
def get_ffr_at_far(scores, labels, target_far):
    """æ ¹æ®ç›®æ ‡FARè®¡ç®—å¯¹åº”çš„FFR"""
    fpr, tpr, thresholds = roc_curve(labels, scores, pos_label=1)
    fnr = 1 - tpr  # FFR = 1 - TPR
    idx = np.argmin(np.abs(fpr - target_far))
    return fnr[idx], thresholds[idx], fpr[idx]


# ============================================================
# ä¸»æµç¨‹ï¼ˆé‡æ„åï¼‰
# ============================================================
def main():
    # 1. åŠ è½½æ¨¡å‹
    print("åŠ è½½æ¨¡å‹...")
    extractor: DeepPrintExtractor = get_DeepPrint_TexMinu(
        num_training_subjects=8000, 
        num_dims=256
    )
    extractor.load_best_model(MODEL_DIR)
    extractor.model.eval()  # è¯„ä¼°æ¨¡å¼

    # 2. åŠ è½½è‡ªå®šä¹‰æ•°æ®é›†ï¼ˆåŸºäºé¡¹ç›®åŸç”ŸImageLoader+Datasetï¼‰
    print("åŠ è½½è‡ªå®šä¹‰æ•°æ®é›†...")
    # åˆå§‹åŒ–è‡ªå®šä¹‰åŠ è½½å™¨
    custom_loader = MyFingerprintLoader(root_dir=CUSTOM_DATA_DIR)
    # å°è£…ä¸ºé¡¹ç›®åŸç”ŸDatasetï¼ˆå…¼å®¹åç»­è¯„ä¼°é€»è¾‘ï¼‰
    custom_dataset = Dataset(data_loader=custom_loader, identifier_set=custom_loader.ids)

    # 3. æå–ç‰¹å¾åµŒå…¥ï¼ˆçº¹ç†+ç»†èŠ‚ç‚¹ï¼‰
    print("æå–ç‰¹å¾åµŒå…¥...")
    texture_embeddings, minutia_embeddings = extractor.extract(custom_dataset)
    embeddings = EmbeddingLoader.combine(texture_embeddings, minutia_embeddings)  # åˆå¹¶ç‰¹å¾

    # å¯é€‰ï¼šè¿‡æ»¤é‡‡é›†æ¬¡æ•°ä¸è¶³4æ¬¡çš„ä¸»ä½“ï¼ˆé¿å…åŸºå‡†åˆ›å»ºæŠ¥é”™ï¼‰
    valid_subjects = []
    subject_impression_count = {}
    # ç»Ÿè®¡æ¯ä¸ªä¸»ä½“çš„é‡‡é›†æ¬¡æ•°
    for id_obj in custom_dataset.ids:
        subject = id_obj.subject
        subject_impression_count[subject] = subject_impression_count.get(subject, 0) + 1
    # åªä¿ç•™é‡‡é›†æ¬¡æ•°â‰¥4çš„ä¸»ä½“
    valid_subjects = [subj for subj, cnt in subject_impression_count.items() if cnt >= 4]

    # åˆ›å»ºéªŒè¯åŸºå‡†ï¼ˆç”¨è¿‡æ»¤åçš„æœ‰æ•ˆä¸»ä½“ï¼‰
    benchmark = create_verification_benchmark(
        subjects=valid_subjects,
        impressions_per_subject=list(range(NUM_IMPRESSIONS_PER_SUBJECT))
    )
    print(f"âš ï¸  è¿‡æ»¤åæœ‰æ•ˆä¸»ä½“æ•°ï¼š{len(valid_subjects)}ï¼ˆåŸ1499ï¼‰")

    # 5. ä½™å¼¦ç›¸ä¼¼åº¦åŒ¹é…
    print("è¿è¡ŒåŒ¹é…æµ‹è¯•...")
    matcher = CosineSimilarityMatcher(embeddings)
    results = benchmark.run(matcher)

    # 6. æ•´ç†åˆ†æ•°å’Œæ ‡ç­¾
    mated_scores = results.get_mated_scores()    # åŒä¸€æ‰‹æŒ‡çš„åŒ¹é…åˆ†æ•°ï¼ˆæ­£æ ·æœ¬ï¼‰
    non_mated_scores = results.get_non_mated_scores()  # ä¸åŒæ‰‹æŒ‡çš„åŒ¹é…åˆ†æ•°ï¼ˆè´Ÿæ ·æœ¬ï¼‰
    all_scores = np.concatenate([mated_scores, non_mated_scores])
    all_labels = np.concatenate([
        np.ones_like(mated_scores),   # æ­£æ ·æœ¬æ ‡ç­¾=1
        np.zeros_like(non_mated_scores)  # è´Ÿæ ·æœ¬æ ‡ç­¾=0
    ])

    # 7. è®¡ç®—EER
    eer = results.get_equal_error_rate()
    print(f"\nEqual-Error-Rate (EER): {eer:.6f} ({eer*100:.4f}%)")

    # 8. è®¡ç®—æŒ‡å®šFARå¯¹åº”çš„FFR
    print("\n===== FARä¸å¯¹åº”çš„FFR =====")
    print(f"{'ç›®æ ‡FAR':<12} {'å®é™…FAR':<12} {'FFR':<12} {'é˜ˆå€¼':<10}")
    print("-" * 50)
    for target_far in TARGET_FAR_VALUES:
        ffr, threshold, actual_far = get_ffr_at_far(all_scores, all_labels, target_far)
        print(f"{target_far:<12.6f} {actual_far:<12.6f} {ffr:<12.6f} {threshold:<10.4f}")

    # 9. ç»˜åˆ¶DETæ›²çº¿
    print("\nç»˜åˆ¶DETæ›²çº¿...")
    plot_verification_results(
        DET_FIGURE_PATH,
        results=[results],
        model_labels=["DeepPrint_TexMinu_Custom"],
        plot_title="Custom Fingerprint Dataset - Verification Performance"
    )
    print(f"DETæ›²çº¿å·²ä¿å­˜è‡³: {DET_FIGURE_PATH}")


if __name__ == "__main__":
    main()